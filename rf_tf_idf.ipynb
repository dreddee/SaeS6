{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# avent apprentisage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_simple(data):\n",
    "    size_vocabulary = 1000\n",
    "    vectorizer = TfidfVectorizer(stop_words = \"english\", max_features = size_vocabulary,ngram_range=(1, 2))\n",
    "    X = vectorizer.fit_transform(data)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_dict = {\n",
    "    \"simple\": retrieve_simple\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_embedding(data, method=\"simple\"):\n",
    "    if method in embedded_dict:\n",
    "        return embedded_dict[method](data)\n",
    "    else:\n",
    "        raise Exception(\"Methode non implementé\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_csv('../V0/ratings_formatted.csv').head(10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "1    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "Name: summary, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings['summary'] = list(retrieve_simple(ratings['summary']).toarray())\n",
    "ratings['comment'] = list(retrieve_simple(ratings['comment']).toarray())\n",
    "ratings['summary'].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings =ratings.drop(columns=['Titre'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_simple = ratings.drop(columns=['rating'])\n",
    "Y_simple = ratings['rating'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   summary_0  summary_1  summary_2  summary_3  summary_4  summary_5  \\\n",
      "0        0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "1        0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "\n",
      "   summary_6  summary_7  summary_8  summary_9  ...  summary_990  summary_991  \\\n",
      "0        0.0        0.0        0.0        0.0  ...          0.0          0.0   \n",
      "1        0.0        0.0        0.0        0.0  ...          0.0          0.0   \n",
      "\n",
      "   summary_992  summary_993  summary_994  summary_995  summary_996  \\\n",
      "0          0.0          0.0          0.0          0.0          0.0   \n",
      "1          0.0          0.0          0.0          0.0          0.0   \n",
      "\n",
      "   summary_997  summary_998  summary_999  \n",
      "0          0.0          0.0          0.0  \n",
      "1          0.0          0.0          0.0  \n",
      "\n",
      "[2 rows x 1000 columns]\n",
      "   comment_0  comment_1  comment_2  comment_3  comment_4  comment_5  \\\n",
      "0        0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "1        0.0        0.0        0.0        0.0        0.0        0.0   \n",
      "\n",
      "   comment_6  comment_7  comment_8  comment_9  ...  comment_990  comment_991  \\\n",
      "0        0.0        0.0        0.0        0.0  ...          0.0          0.0   \n",
      "1        0.0        0.0        0.0        0.0  ...          0.0          0.0   \n",
      "\n",
      "   comment_992  comment_993  comment_994  comment_995  comment_996  \\\n",
      "0     0.207759          0.0          0.0          0.0          0.0   \n",
      "1     0.000000          0.0          0.0          0.0          0.0   \n",
      "\n",
      "   comment_997  comment_998  comment_999  \n",
      "0          0.0          0.0          0.0  \n",
      "1          0.0          0.0          0.0  \n",
      "\n",
      "[2 rows x 1000 columns]\n"
     ]
    }
   ],
   "source": [
    "# 1. Convertir les colonnes matrices en colonnes individuelles\n",
    "def expand_matrix_column(df, column_name):\n",
    "    # Convertir la liste de listes en array numpy\n",
    "    matrix = np.array(df[column_name].tolist())\n",
    "    # Créer des noms de colonnes\n",
    "    column_names = [f\"{column_name}_{i}\" for i in range(matrix.shape[1])]\n",
    "    # Retourner un nouveau DataFrame avec les colonnes expandées\n",
    "    print(pd.DataFrame(matrix, columns=column_names).head(2))\n",
    "    return pd.DataFrame(matrix, columns=column_names)\n",
    "\n",
    "# 2. Appliquer la transformation sur chaque colonne contenant une matrice\n",
    "X_expanded = pd.concat([\n",
    "    expand_matrix_column(ratings, 'summary'),\n",
    "    expand_matrix_column(ratings, 'comment')\n",
    "], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.59\n"
     ]
    }
   ],
   "source": [
    "# 3. Maintenant on peut utiliser ces données pour l'entraînement\n",
    "X_simple_train, X_simple_test, y_simple_train, y_simple_test = train_test_split(X_expanded, Y_simple, test_size=0.2)\n",
    "model_rf = RandomForestClassifier(n_estimators=100)\n",
    "model_rf.fit(X_simple_train, y_simple_train)\n",
    "\n",
    "# Prédiction et évaluation\n",
    "y_pred = model_rf.predict(X_simple_test)\n",
    "accuracy = accuracy_score(y_simple_test, y_pred)\n",
    "print(f'Random Forest Accuracy: {accuracy:.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.57\n"
     ]
    }
   ],
   "source": [
    "# 3. Maintenant on peut utiliser ces données pour l'entraînement\n",
    "X_simple_train, X_simple_test, y_simple_train, y_simple_test = train_test_split(X_expanded, Y_simple, test_size=0.2)\n",
    "model_rf = KNeighborsClassifier(n_neighbors=5)\n",
    "model_rf.fit(X_simple_train, y_simple_train)\n",
    "\n",
    "# Prédiction et évaluation\n",
    "y_pred = model_rf.predict(X_simple_test)\n",
    "accuracy = accuracy_score(y_simple_test, y_pred)\n",
    "print(f'Random Forest Accuracy: {accuracy:.2f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
