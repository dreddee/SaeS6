{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'ratings_formatted.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m ratings \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mratings_formatted.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ray-h\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    945\u001b[0m )\n\u001b[0;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ray-h\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\ray-h\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ray-h\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1706\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1712\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1714\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\ray-h\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    865\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    866\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    867\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    868\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'ratings_formatted.csv'"
     ]
    }
   ],
   "source": [
    "ratings = pd.read_csv('ratings_formatted.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "comments_short = ratings['summary'].dropna().head(100000).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Nice collection of Julie Strain images', 'Really Enjoyed It',\n",
       "       'Essential for every personal and Public Library', ...,\n",
       "       'Highly suggested for beginners',\n",
       "       'Good for the beginner, nice paper for the experienced',\n",
       "       'Greate Activity Book for Kids'], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_short"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mots simples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_vocabulary = 1000\n",
    "vectorizer = CountVectorizer(stop_words = \"english\", max_features = size_vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 1000)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = vectorizer.fit_transform(comments_short)\n",
    "X.toarray().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_vocabulary = 1000\n",
    "vectorizer = TfidfVectorizer(stop_words = \"english\", max_features = size_vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 1000)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = vectorizer.fit_transform(comments_short)\n",
    "X.toarray().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['000', '10', '100', '11', '12', '1491', '1984', '20', '20th', '34',\n",
       "       '451', '65533', 'absolute', 'absolutely', 'account', 'accurate',\n",
       "       'action', 'actually', 'addition', 'adult', 'adults', 'adventure',\n",
       "       'adventures', 'advice', 'age', 'ages', 'ago', 'agree', 'ahead',\n",
       "       'alive', 'amazing', 'amazon', 'america', 'american', 'americans',\n",
       "       'amp', 'amusing', 'analysis', 'ancient', 'anger', 'anti',\n",
       "       'approach', 'april', 'art', 'asimov', 'attention', 'audio',\n",
       "       'audiobook', 'auel', 'austen', 'author', 'authors',\n",
       "       'autobiography', 'available', 'average', 'away', 'awesome',\n",
       "       'awful', 'awsome', 'ayla', 'baby', 'bad', 'baseball', 'based',\n",
       "       'basic', 'basics', 'bear', 'beautiful', 'beautifully', 'beauty',\n",
       "       'beginner', 'beginners', 'beginning', 'believe', 'best', 'better',\n",
       "       'beware', 'biased', 'bible', 'biblical', 'big', 'bilbo',\n",
       "       'biography', 'bit', 'black', 'blackbird', 'boleyn', 'book',\n",
       "       'books', 'boring', 'bother', 'bought', 'boy', 'boys', 'bradbury',\n",
       "       'brain', 'breathtaking', 'brilliant', 'brings', 'brooklyn',\n",
       "       'brother', 'building', 'burn', 'burning', 'business', 'buy',\n",
       "       'came', 'camus', 'cannery', 'captivating', 'care', 'carter',\n",
       "       'case', 'casterbridge', 'cat', 'catholic', 'cave', 'cd',\n",
       "       'censorship', 'century', 'challenging', 'change', 'changed',\n",
       "       'changing', 'chapter', 'character', 'characters', 'charming',\n",
       "       'chi', 'child', 'childhood', 'children', 'chilling', 'choice',\n",
       "       'christian', 'christianity', 'christians', 'christmas', 'church',\n",
       "       'city', 'civil', 'clan', 'class', 'classic', 'classics', 'clear',\n",
       "       'clever', 'close', 'cold', 'collection', 'collector', 'college',\n",
       "       'come', 'comes', 'comic', 'coming', 'commentary', 'common',\n",
       "       'companion', 'compelling', 'complete', 'completely', 'complex',\n",
       "       'comprehensive', 'concept', 'concise', 'condition', 'confusing',\n",
       "       'content', 'continues', 'cookbook', 'cookie', 'cooking', 'cooky',\n",
       "       'cool', 'copy', 'cornwell', 'couldn', 'count', 'course', 'cover',\n",
       "       'creative', 'creepy', 'crime', 'cristo', 'crochet', 'culture',\n",
       "       'cute', 'dark', 'darkness', 'date', 'dated', 'daughter', 'david',\n",
       "       'dawn', 'day', 'days', 'dead', 'deal', 'death', 'decent', 'deep',\n",
       "       'defense', 'definitely', 'definitive', 'delicious', 'delight',\n",
       "       'delightful', 'delivery', 'depressing', 'depth', 'description',\n",
       "       'desert', 'deserves', 'design', 'despite', 'detailed', 'details',\n",
       "       'development', 'diabetes', 'dickens', 'dictionary', 'did', 'didn',\n",
       "       'different', 'difficult', 'disappointed', 'disappointing',\n",
       "       'disappointment', 'discworld', 'disturbing', 'does', 'doesn',\n",
       "       'dog', 'don', 'dont', 'dr', 'dragon', 'drama', 'dream', 'dreams',\n",
       "       'dry', 'dull', 'dummies', 'dune', 'dystopian', 'early', 'earth',\n",
       "       'easy', 'economics', 'edge', 'edition', 'editor', 'education',\n",
       "       'educational', 'effective', 'effort', 'emma', 'emotional',\n",
       "       'empire', 'enchanting', 'encyclopedia', 'end', 'ending',\n",
       "       'engaging', 'english', 'engrossing', 'enjoy', 'enjoyable',\n",
       "       'enjoyed', 'enlightening', 'entertaining', 'epic', 'era', 'eragon',\n",
       "       'errors', 'especially', 'essential', 'esv', 'evil', 'exactly',\n",
       "       'exam', 'example', 'excellent', 'exceptional', 'exciting',\n",
       "       'expect', 'expectations', 'expected', 'experience',\n",
       "       'extraordinary', 'extremely', 'eye', 'eyes', 'fabulous', 'face',\n",
       "       'fact', 'facts', 'fahrenheit', 'fair', 'faith', 'fall', 'falls',\n",
       "       'family', 'fan', 'fans', 'fantastic', 'fantasy', 'far',\n",
       "       'fascinating', 'fast', 'father', 'favorite', 'favorites',\n",
       "       'favourite', 'feel', 'female', 'fi', 'fiction', 'field', 'finally',\n",
       "       'fine', 'finest', 'finish', 'flawed', 'flaws', 'flies', 'follow',\n",
       "       'food', 'forever', 'forget', 'forgotten', 'form', 'format',\n",
       "       'foundation', 'franklin', 'free', 'freedom', 'french', 'fresh',\n",
       "       'friend', 'friends', 'frightening', 'fun', 'funny', 'future',\n",
       "       'game', 'garbage', 'garwood', 'gem', 'general', 'generation',\n",
       "       'genius', 'genre', 'george', 'german', 'gets', 'getting', 'gift',\n",
       "       'girl', 'girls', 'gives', 'glad', 'god', 'gods', 'goes', 'going',\n",
       "       'golden', 'gone', 'good', 'got', 'grade', 'grand', 'great',\n",
       "       'greatest', 'gripping', 'grisham', 'ground', 'growing', 'grows',\n",
       "       'guide', 'guy', 'half', 'halo', 'hand', 'hands', 'happened',\n",
       "       'happy', 'hard', 'hardy', 'harry', 'hate', 'hated', 'haunting',\n",
       "       'haven', 'heart', 'heartwarming', 'heaven', 'hell', 'help',\n",
       "       'helpful', 'henry', 'hero', 'high', 'highly', 'hilarious',\n",
       "       'historical', 'history', 'hit', 'hobbit', 'holmes', 'holy', 'home',\n",
       "       'honest', 'hooked', 'hope', 'horrible', 'horror', 'hot', 'hound',\n",
       "       'house', 'human', 'humanity', 'humor', 'humorous', 'hype', 'idea',\n",
       "       'ideas', 'ii', 'illustrated', 'illustrations', 'imagination',\n",
       "       'imaginative', 'important', 'impressive', 'incomplete',\n",
       "       'incredible', 'incredibly', 'info', 'information', 'informative',\n",
       "       'inside', 'insight', 'insightful', 'insights', 'inspiration',\n",
       "       'inspirational', 'inspired', 'inspiring', 'instead',\n",
       "       'intellectual', 'intelligent', 'interested', 'interesting',\n",
       "       'intriguing', 'intro', 'introduction', 'island', 'isn', 'issues',\n",
       "       'jack', 'james', 'jane', 'java', 'jean', 'jesus', 'jim', 'job',\n",
       "       'john', 'journal', 'journey', 'joy', 'joyce', 'julia', 'julie',\n",
       "       'juror', 'just', 'keeps', 'kerouac', 'key', 'kid', 'kids', 'kind',\n",
       "       'kindle', 'king', 'kings', 'know', 'knowledge', 'known', 'la',\n",
       "       'lacking', 'lacks', 'land', 'language', 'late', 'later', 'laugh',\n",
       "       'learn', 'learned', 'learning', 'leaves', 'left', 'legend',\n",
       "       'lesson', 'lessons', 'let', 'letter', 'level', 'lewis', 'library',\n",
       "       'life', 'light', 'like', 'liked', 'line', 'list', 'listen',\n",
       "       'literary', 'literature', 'little', 'live', 'lives', 'living',\n",
       "       'll', 'logic', 'long', 'look', 'looking', 'looks', 'lord', 'lost',\n",
       "       'lot', 'lots', 'love', 'loved', 'lovely', 'lover', 'lovers',\n",
       "       'loves', 'loving', 'low', 'magic', 'magical', 'magnificent',\n",
       "       'major', 'make', 'makes', 'making', 'man', 'management', 'manual',\n",
       "       'mark', 'mars', 'marvelous', 'mary', 'master', 'masterful',\n",
       "       'masterpiece', 'material', 'matter', 'maybe', 'mayor', 'meaning',\n",
       "       'mediocre', 'meets', 'memoir', 'memories', 'men', 'mere',\n",
       "       'message', 'mice', 'middle', 'mind', 'misleading', 'miss',\n",
       "       'missed', 'missing', 'mixed', 'modern', 'money', 'monte', 'moral',\n",
       "       'morning', 'mother', 'movie', 'moving', 'mr', 'ms', 'murder',\n",
       "       'music', 'mystery', 'narrative', 'nature', 'necessary', 'need',\n",
       "       'needed', 'needs', 'new', 'nice', 'night', 'non', 'novel',\n",
       "       'novels', 'oh', 'ok', 'okay', 'old', 'open', 'opener', 'opening',\n",
       "       'opera', 'opinion', 'order', 'original', 'orwell', 'outdated',\n",
       "       'outstanding', 'overall', 'overrated', 'overview', 'paced',\n",
       "       'packed', 'page', 'pages', 'paolini', 'paper', 'parents', 'pass',\n",
       "       'past', 'patterns', 'people', 'perfect', 'period', 'person',\n",
       "       'personal', 'perspective', 'philosophy', 'photos', 'physics',\n",
       "       'picture', 'pictures', 'piece', 'place', 'plain', 'play',\n",
       "       'pleasant', 'pleased', 'pleasure', 'plot', 'poetic', 'poetry',\n",
       "       'poignant', 'point', 'political', 'politics', 'pond', 'poor',\n",
       "       'poorly', 'portrait', 'possible', 'possibly', 'post', 'potential',\n",
       "       'potter', 'power', 'powerful', 'practical', 'pratchett', 'pre',\n",
       "       'predictable', 'premise', 'present', 'presentation', 'pretty',\n",
       "       'price', 'primer', 'princess', 'print', 'probably', 'problem',\n",
       "       'problems', 'product', 'profound', 'prophetic', 'prose',\n",
       "       'provoking', 'psychology', 'public', 'published', 'purchase',\n",
       "       'pure', 'quality', 'question', 'questions', 'quick', 'quite',\n",
       "       'quot', 'rare', 'rate', 'rated', 'rating', 'read', 'readable',\n",
       "       'reader', 'readers', 'reading', 'reads', 'real', 'realism',\n",
       "       'realistic', 'reality', 'really', 'reason', 'recipes', 'recommend',\n",
       "       'recommended', 'red', 'reference', 'refreshing', 'relationship',\n",
       "       'relevant', 'religion', 'religious', 'remarkable', 'remember',\n",
       "       'repetitive', 'required', 'research', 'researched', 'resource',\n",
       "       'rest', 'revenge', 'review', 'reviews', 'revolution', 'rich',\n",
       "       'ride', 'right', 'rings', 'riveting', 'road', 'rocks', 'romance',\n",
       "       'romantic', 'row', 'rules', 'run', 'running', 'sad', 'saga',\n",
       "       'said', 'satire', 'satisfied', 'satisfying', 'save', 'say', 'says',\n",
       "       'scarlet', 'scary', 'school', 'sci', 'science', 'scifi', 'sea',\n",
       "       'search', 'second', 'secret', 'sedaris', 'seen', 'self', 'seller',\n",
       "       'sense', 'sequel', 'series', 'service', 'set', 'sex', 'sf',\n",
       "       'shakespeare', 'shelters', 'short', 'shows', 'silver', 'simple',\n",
       "       'simply', 'single', 'size', 'skip', 'slavery', 'sleep', 'slow',\n",
       "       'small', 'smart', 'smith', 'social', 'society', 'soldier', 'solid',\n",
       "       'somewhat', 'son', 'sorry', 'soul', 'source', 'south', 'space',\n",
       "       'special', 'spectacular', 'spirit', 'spiritual', 'standard',\n",
       "       'star', 'stars', 'start', 'started', 'starting', 'starts',\n",
       "       'statistics', 'steinbeck', 'step', 'stone', 'stop', 'stories',\n",
       "       'story', 'storytelling', 'strange', 'stranger', 'strong',\n",
       "       'student', 'students', 'study', 'stuff', 'stunning', 'stupid',\n",
       "       'style', 'subject', 'substance', 'success', 'summary', 'summer',\n",
       "       'super', 'superb', 'sure', 'surprise', 'surprised', 'surprising',\n",
       "       'surprisingly', 'survival', 'suspense', 'suspenseful', 'sweet',\n",
       "       'takes', 'tale', 'tales', 'talk', 'teacher', 'teachers',\n",
       "       'teaching', 'technical', 'tedious', 'teens', 'tell', 'telling',\n",
       "       'terrible', 'terrific', 'tess', 'test', 'text', 'textbook',\n",
       "       'thank', 'thanks', 'theology', 'theory', 'thing', 'things',\n",
       "       'think', 'thinking', 'thomas', 'thorough', 'thoroughly', 'thought',\n",
       "       'thoughtful', 'thoughts', 'thriller', 'thrilling', 'thumbs',\n",
       "       'time', 'timeless', 'times', 'title', 'today', 'told', 'tolkien',\n",
       "       'tom', 'tool', 'topic', 'total', 'totally', 'touch', 'touching',\n",
       "       'tough', 'tour', 'town', 'tragedy', 'tragic', 'translation',\n",
       "       'travel', 'treasure', 'treat', 'tree', 'trilogy', 'trip', 'true',\n",
       "       'truly', 'truth', 'try', 'turn', 'turner', 'twain', 'twist',\n",
       "       'type', 'typical', 'ultimate', 'ulysses', 'unbelievable',\n",
       "       'understand', 'understanding', 'unforgettable', 'unique',\n",
       "       'universe', 'unusual', 'uplifting', 'use', 'used', 'useful',\n",
       "       'usual', 'valuable', 'value', 've', 'version', 'victorian', 'view',\n",
       "       'vision', 'vivid', 'voice', 'volume', 'vs', 'wait', 'waiting',\n",
       "       'wake', 'want', 'wanted', 'war', 'warning', 'warriors', 'wars',\n",
       "       'wasn', 'waste', 'watch', 'way', 'ways', 'weak', 'weird',\n",
       "       'welcome', 'west', 'western', 'white', 'wild', 'winner', 'wisdom',\n",
       "       'wish', 'witch', 'witty', 'woman', 'women', 'won', 'wonderful',\n",
       "       'wonderfully', 'word', 'words', 'work', 'works', 'world', 'worst',\n",
       "       'worth', 'worthwhile', 'worthy', 'wow', 'write', 'writer',\n",
       "       'writers', 'writing', 'written', 'wrong', 'wrote', 'wwii', 'year',\n",
       "       'years', 'yes', 'young', 'younger'], dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bert embbeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "def get_bert_latent_representation(text,model,tokenizer):\n",
    "   \n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    cls_embedding = outputs.last_hidden_state[:, 0, :]\n",
    "    \n",
    "    return cls_embedding\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latent representation shape: torch.Size([1, 768])\n"
     ]
    }
   ],
   "source": [
    "sample_text = comments_short[0]\n",
    "latent_representation = get_bert_latent_representation(sample_text,model,tokenizer)\n",
    "print(\"Latent representation shape:\", latent_representation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
